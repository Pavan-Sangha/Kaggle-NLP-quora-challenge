{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport string\nfrom matplotlib import pyplot\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n             \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \n             \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \n             \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \n             \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \n             \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \n             \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \n             \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \n             \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \n             \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \n             \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "61c80feafbf3dfd1a921886589ba1225b880b7b6"
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "69ef01644b7a56269cd970ff9ad73d710ee8f34e",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "index_train = train.shape[0]-1\nindex_train",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "583ebee743d930a7d82597e3281f9b577a2bed14"
      },
      "cell_type": "code",
      "source": "# concatenate data for tfidf vectorizer\ndata = pd.concat([train[['qid','question_text']],test],ignore_index = True)\n\ny_train = train.iloc[:,2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c98c423ad337cfbf22e898efb15d2207d05f28da"
      },
      "cell_type": "code",
      "source": "### Check split points are ok \n\nprint(train.iloc[1306121,1] == data.iloc[1306121,1])\nprint(test.iloc[0,1] == data.iloc[1306122,1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8a415bd0a620bf1bdbd163e51be2e61bea091483"
      },
      "cell_type": "code",
      "source": "data.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a96e59c0691d153932ed95ff36222a84390df87a"
      },
      "cell_type": "markdown",
      "source": "## Vectorising the data\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "33749faf7e40bad1fb1e8bbe90416b0eb439f40c"
      },
      "cell_type": "code",
      "source": "def clean_text_tfidf(text):\n    \n    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n    tokens = re.split('\\W+', text)\n    text = [word for word in tokens if word not in stopwords]\n    return text",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b3efb0fcca8b3dbd190f2e24fe37061c57117806"
      },
      "cell_type": "code",
      "source": "tfidf_vect = TfidfVectorizer(analyzer=clean_text_tfidf)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f16c4e15f5e9a5f0753e8ee64174495a90074057"
      },
      "cell_type": "code",
      "source": "data_tfidf = tfidf_vect.fit_transform(data['question_text'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95ed59c98cc7a1de79aeb9c63fd4127232f181b7"
      },
      "cell_type": "code",
      "source": "train_tfidf = data_tfidf[:index_train+1,:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ba01951732524e812fb78725179cd1bbdd974836"
      },
      "cell_type": "markdown",
      "source": "## Fitting an XGBoost Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6514e60ae7b4570e41c8aabdd3e34a2fe47af16e"
      },
      "cell_type": "code",
      "source": "from xgboost.sklearn import XGBClassifier",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "92a93480c258b4affeefae201c009b5bf4df42bc"
      },
      "cell_type": "code",
      "source": "xgb = XGBClassifier()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ab9e959305c459c0f43a25b424bc42451ff05180"
      },
      "cell_type": "code",
      "source": "xgb.fit(train_tfidf,y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dc7b66fd2cb35b027221f47f222ae964dc92aa8d"
      },
      "cell_type": "markdown",
      "source": "## Predicting on test set"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53bf586dea1bf26b440b7b7068cdf8714ac0651e"
      },
      "cell_type": "code",
      "source": "test_tfidf = data_tfidf[index_train+1:,:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "72d625c7bcfc5fb83960edb17216f9013c8e5fef"
      },
      "cell_type": "code",
      "source": "pred = xgb.predict(test_tfidf)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ed09673ecad1ec73b5c27ca0b5c31e42444c0627"
      },
      "cell_type": "code",
      "source": "len(pred)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e4c7d625550ae8605ff7bd46578ebcacd0445c39"
      },
      "cell_type": "code",
      "source": "test.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a625b450174cbe4d491009cd5f19aefe07ee478b"
      },
      "cell_type": "code",
      "source": "out_df = pd.DataFrame({\"qid\":test[\"qid\"].values})\nout_df['prediction'] = pred\nout_df.to_csv(\"submission.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f19eff3b71a433d2735daacf0e2d1b2a51a839cf"
      },
      "cell_type": "markdown",
      "source": ""
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}